{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a80c1264cf34523a2f99cd784a81262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f28aa8d6fc54579a3ee11bd8ad7ea06",
              "IPY_MODEL_5e48c7ea3cc348339d8e4e72bd98b452",
              "IPY_MODEL_6b11e82598fe4ba49cb8d1628edb8a7c"
            ],
            "layout": "IPY_MODEL_0ebbf20a938546d78b377d4539166e6f"
          }
        },
        "0f28aa8d6fc54579a3ee11bd8ad7ea06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b2e758d09844bea2d84e01a6ba4ed7",
            "placeholder": "​",
            "style": "IPY_MODEL_a94cb61a27ec44b18be86ab25d7d6250",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5e48c7ea3cc348339d8e4e72bd98b452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2829682f055b418f9204adb314ec058c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3b79b3ed456483a967c9069e4877ee1",
            "value": 2
          }
        },
        "6b11e82598fe4ba49cb8d1628edb8a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18388e3fd4c8449685b43403c5347ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_b183ea77dfb5422ba1dbc4625a5a9f56",
            "value": " 2/2 [00:38&lt;00:00, 17.35s/it]"
          }
        },
        "0ebbf20a938546d78b377d4539166e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b2e758d09844bea2d84e01a6ba4ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94cb61a27ec44b18be86ab25d7d6250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2829682f055b418f9204adb314ec058c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b79b3ed456483a967c9069e4877ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18388e3fd4c8449685b43403c5347ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b183ea77dfb5422ba1dbc4625a5a9f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "model_dir = \"./phi2-text2sql\"  # Your output directory\n",
        "checkpoints = [f for f in os.listdir(model_dir) if f.startswith(\"checkpoint\")]\n",
        "print(\"Available Checkpoints:\", checkpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWtr5ZCEWhgq",
        "outputId": "efbcecca-ef16-45b9-9d2b-56b054a599d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Checkpoints: ['checkpoint-250', 'checkpoint-350']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))[-1]  # Sort numerically\n",
        "checkpoint_path = os.path.join(model_dir, latest_checkpoint)\n",
        "\n",
        "print(\"Using checkpoint:\", checkpoint_path)\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load the latest checkpoint\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
        "model.eval()  # Set to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a80c1264cf34523a2f99cd784a81262",
            "0f28aa8d6fc54579a3ee11bd8ad7ea06",
            "5e48c7ea3cc348339d8e4e72bd98b452",
            "6b11e82598fe4ba49cb8d1628edb8a7c",
            "0ebbf20a938546d78b377d4539166e6f",
            "35b2e758d09844bea2d84e01a6ba4ed7",
            "a94cb61a27ec44b18be86ab25d7d6250",
            "2829682f055b418f9204adb314ec058c",
            "c3b79b3ed456483a967c9069e4877ee1",
            "18388e3fd4c8449685b43403c5347ac7",
            "b183ea77dfb5422ba1dbc4625a5a9f56"
          ]
        },
        "id": "NgxEzXNSXBCl",
        "outputId": "c92342c5-afa7-45ed-e7c9-4e128f382125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using checkpoint: ./phi2-text2sql/checkpoint-350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a80c1264cf34523a2f99cd784a81262"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PhiForCausalLM(\n",
              "  (model): PhiModel(\n",
              "    (embed_tokens): Embedding(51200, 2560)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x PhiDecoderLayer(\n",
              "        (self_attn): PhiAttention(\n",
              "          (q_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (k_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (v_proj): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (dense): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2560, out_features=2560, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "        )\n",
              "        (mlp): PhiMLP(\n",
              "          (activation_fn): NewGELUActivation()\n",
              "          (fc1): lora.Linear(\n",
              "            (base_layer): Linear(in_features=2560, out_features=10240, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=2560, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=10240, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (fc2): lora.Linear(\n",
              "            (base_layer): Linear(in_features=10240, out_features=2560, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=10240, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=2560, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "        )\n",
              "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (rotary_emb): PhiRotaryEmbedding()\n",
              "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_sql(query, model, tokenizer, max_length=200):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\").to(\"cpu\")\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_length=max_length)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "import re\n",
        "\n",
        "def generate_sql(user_query, model, tokenizer):\n",
        "    input_ids = tokenizer.encode(user_query, return_tensors=\"pt\")\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=100,\n",
        "        do_sample=False,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "# Example user query\n",
        "user_query = \"\"\"\n",
        "## INPUT\n",
        "Query: Find the total revenue generated in the year 2004.\n",
        "\n",
        "## OUTPUT\n",
        "SQL query:\n",
        "\"\"\"\n",
        "\n",
        "# Generate SQL from the model (Make sure `model` and `tokenizer` are defined)\n",
        "generated_sql = generate_sql(user_query, model, tokenizer)\n",
        "\n",
        "# Example output from the model (if already available)\n",
        "generated_output = \"\"\"\n",
        "## INPUT\n",
        "Query: Find the total revenue generated in the year 2004.\n",
        "\n",
        "## OUTPUT\n",
        "SQL query:\n",
        "SELECT SUM(revenue) FROM orders WHERE order_date BETWEEN '2004-01-01' AND '2004-12-31';\n",
        "\"\"\"\n",
        "\n",
        "# Extract only the SQL query using regex\n",
        "matches = re.findall(r\"SQL query:\\s*(SELECT.*?);\", generated_output, re.DOTALL)\n",
        "\n",
        "# Get the last (or first) SQL query found\n",
        "cleaned_sql = matches[-1] + \";\" if matches else \"No valid SQL found.\"\n",
        "\n",
        "print(\"Purified SQL Output:\", cleaned_sql)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKYKwJ_2W7Cm",
        "outputId": "16ca0b5b-dc2a-43a5-e121-374324809fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purified SQL Output: SELECT SUM(revenue) FROM orders WHERE order_date BETWEEN '2004-01-01' AND '2004-12-31';\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r phi2-text2sql-finetuned.zip phi2-text2sql/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5CKcK0HcTHF",
        "outputId": "78068e96-d761-4fdc-cb14-096ae0ed8ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: phi2-text2sql/ (stored 0%)\n",
            "  adding: phi2-text2sql/checkpoint-250/ (stored 0%)\n",
            "  adding: phi2-text2sql/checkpoint-250/merges.txt (deflated 53%)\n",
            "  adding: phi2-text2sql/checkpoint-250/adapter_model.safetensors (deflated 7%)\n",
            "  adding: phi2-text2sql/checkpoint-250/scheduler.pt (deflated 56%)\n",
            "  adding: phi2-text2sql/checkpoint-250/special_tokens_map.json (deflated 75%)\n",
            "  adding: phi2-text2sql/checkpoint-250/vocab.json (deflated 59%)\n",
            "  adding: phi2-text2sql/checkpoint-250/tokenizer_config.json (deflated 94%)\n",
            "  adding: phi2-text2sql/checkpoint-250/added_tokens.json (deflated 84%)\n",
            "  adding: phi2-text2sql/checkpoint-250/README.md (deflated 66%)\n",
            "  adding: phi2-text2sql/checkpoint-250/training_args.bin (deflated 51%)\n",
            "  adding: phi2-text2sql/checkpoint-250/tokenizer.json (deflated 82%)\n",
            "  adding: phi2-text2sql/checkpoint-250/adapter_config.json (deflated 55%)\n",
            "  adding: phi2-text2sql/checkpoint-250/optimizer.pt (deflated 9%)\n",
            "  adding: phi2-text2sql/checkpoint-250/rng_state.pth (deflated 25%)\n",
            "  adding: phi2-text2sql/checkpoint-250/trainer_state.json (deflated 78%)\n",
            "  adding: phi2-text2sql/checkpoint-350/ (stored 0%)\n",
            "  adding: phi2-text2sql/checkpoint-350/merges.txt (deflated 53%)\n",
            "  adding: phi2-text2sql/checkpoint-350/adapter_model.safetensors (deflated 7%)\n",
            "  adding: phi2-text2sql/checkpoint-350/scheduler.pt (deflated 56%)\n",
            "  adding: phi2-text2sql/checkpoint-350/special_tokens_map.json (deflated 75%)\n",
            "  adding: phi2-text2sql/checkpoint-350/vocab.json (deflated 59%)\n",
            "  adding: phi2-text2sql/checkpoint-350/tokenizer_config.json (deflated 94%)\n",
            "  adding: phi2-text2sql/checkpoint-350/added_tokens.json (deflated 84%)\n",
            "  adding: phi2-text2sql/checkpoint-350/README.md (deflated 66%)\n",
            "  adding: phi2-text2sql/checkpoint-350/training_args.bin (deflated 51%)\n",
            "  adding: phi2-text2sql/checkpoint-350/tokenizer.json (deflated 82%)\n",
            "  adding: phi2-text2sql/checkpoint-350/adapter_config.json (deflated 55%)\n",
            "  adding: phi2-text2sql/checkpoint-350/optimizer.pt (deflated 9%)\n",
            "  adding: phi2-text2sql/checkpoint-350/rng_state.pth (deflated 25%)\n",
            "  adding: phi2-text2sql/checkpoint-350/trainer_state.json (deflated 79%)\n"
          ]
        }
      ]
    }
  ]
}